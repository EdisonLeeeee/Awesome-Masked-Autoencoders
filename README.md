# Awesome Masked Autoencoders
<img src="https://img.shields.io/badge/Contributions-Welcome-278ea5" alt="Contrib"/> <img src="https://img.shields.io/badge/Number%20of%20Papers-170-FF6F00" alt="PaperNum"/>

<p align="center"> <img width = "700" height = "380" src="mae.png" /> <p align="center">Fig. 1. Masked Autoencoders from Kaiming He et al.</p>

Masked Autoencoder (MAE, *Kaiming He et al.*) has renewed a surge of interest due to its capacity to learn useful representations from rich unlabeled data. Until recently, MAE and its follow-up works have advanced the state-of-the-art and provided valuable insights in research (particularly vision research). Here I list several follow-up works after or concurrent with MAE to inspire future research.


> *:octocat: code link, üåê project page

# Vision
+ [üî•Masked Autoencoders Are Scalable Vision Learners](https://arxiv.org/abs/2111.06377) [:octocat:](https://github.com/FlyEgle/MAE-pytorch) [:octocat:](https://github.com/pengzhiliang/MAE-pytorch) Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll√°r, Ross Girshick
+ [üî•SimMIM: A Simple Framework for Masked Image Modeling](https://arxiv.org/abs/2111.09886) [:octocat:](https://github.com/microsoft/SimMIM) Zhenda Xie, Zheng Zhang, Yue Cao, Yutong Lin, Jianmin Bao, Zhuliang Yao, Qi Dai, Han Hu
+ [üî•BEIT: BERT Pre-Training of Image Transformers](https://arxiv.org/abs/2106.08254) [:octocat:](https://github.com/microsoft/unilm/tree/master/beit) Hangbo Bao, Li Dong, Furu Wei
+ [Student Collaboration Improves Self-Supervised Learning: Dual-Loss Adaptive Masked Autoencoder for Brain Cell Image Analysis](https://arxiv.org/abs/2205.05194) [:octocat:](https://github.com/hula-ai/DAMA) Son T. Ly, Bai Lin, Hung Q. Vo, Dragan Maric, Badri Roysam, Hien V. Nguyen
+ [A Mask-Based Adversarial Defense Scheme](https://arxiv.org/abs/2204.11837) Weizhen Xu, Chenyi Zhang, Fangzhen Zhao, Liangda Fang
+ [Adversarial Masking for Self-Supervised Learning](https://arxiv.org/abs/2201.13100) [:octocat:](https://github.com/YugeTen/adios) Yuge Shi, N. Siddharth, Philip H.S. Torr, Adam R. Kosiorek
+ [Beyond Masking: Demystifying Token-Based Pre-Training for Vision Transformers](https://arxiv.org/abs/2203.14313) [:octocat:](https://github.com/sunsmarterjie/beyond_masking) Yunjie Tian, Lingxi Xie, Jiemin Fang, Mengnan Shi, Junran Peng, Xiaopeng Zhang, Jianbin Jiao, Qi Tian, Qixiang Ye
+ [Context Autoencoder for Self-Supervised Representation Learning](https://arxiv.org/abs/2202.03026) [:octocat:](https://github.com/lxtGH/CAE) Xiaokang Chen, Mingyu Ding, Xiaodi Wang, Ying Xin, Shentong Mo, Yunhao Wang, Shumin Han, Ping Luo, Gang Zeng, Jingdong Wang
+ [Contextual Representation Learning beyond Masked Language Modeling](https://arxiv.org/abs/2204.04163) [:octocat:](https://github.com/FUZHIYI/TACO) Zhiyi Fu, Wangchunshu Zhou, Jingjing Xu, Hao Zhou, Lei Li
+ [ContrastMask: Contrastive Learning to Segment Every Thing](https://arxiv.org/abs/2203.09775) [:octocat:](https://github.com/huiserwang/ContrastMask) Xuehui Wang, Kai Zhao, Ruixin Zhang, Shouhong Ding, Yan Wang, Wei Shen
+ [ConvMAE: Masked Convolution Meets Masked Autoencoders](https://arxiv.org/abs/2205.03892) [:octocat:](https://github.com/Alpha-VL/ConvMAE) Peng Gao, Teli Ma, Hongsheng Li, Ziyi Lin, Jifeng Dai, Yu Qiao
+ [Exploring Plain Vision Transformer Backbones for Object Detection](https://arxiv.org/abs/2203.16527) Yanghao Li, Hanzi Mao, Ross Girshick, Kaiming He
+ [Global Contrast Masked Autoencoders Are Powerful Pathological Representation Learners](https://arxiv.org/abs/2205.09048) [:octocat:](https://github.com/StarUniversus/gcmae) Hao Quan, Xingyu Li, Weixing Chen, Qun Bai, Mingchen Zou, Ruijie Yang, Tingting Zheng, Ruiqun Qi, Xinghua Gao, Xiaoyu Cui
+ [iBOT: Image Bert Pre-Training With Online Tokenizer](https://arxiv.org/abs/2111.07832) [:octocat:](https://github.com/bytedance/ibot) Jinghao Zhou, Chen Wei, Huiyu Wang, Wei Shen, Cihang Xie, Alan Yuille, Tao Kong
+ [MADE: Masked Autoencoder for Distribution Estimation](https://arxiv.org/abs/1502.03509) [:octocat:](https://github.com/mgermain/MADE) Mathieu Germain, Karol Gregor, Iain Murray, Hugo Larochelle
+ [Mask Transfiner for High-Quality Instance Segmentation](https://arxiv.org/abs/2111.13673) [:octocat:](http://vis.xyz/pub/transfiner) Lei Ke, Martin Danelljan, Xia Li, Yu-Wing Tai, Chi-Keung Tang, Fisher Yu
+ [Masked Autoencoders As Spatiotemporal Learners](https://arxiv.org/abs/2205.09113) Christoph Feichtenhofer, Haoqi Fan, Yanghao Li, Kaiming He
+ [Masked Discrimination for Self-Supervised Learning on Point Clouds](https://arxiv.org/abs/2203.11183) [:octocat:](https://github.com/haotian-liu/MaskPoint) Haotian Liu, Mu Cai, Yong Jae Lee
+ [Masked Feature Prediction for Self-Supervised Visual Pre-Training](https://arxiv.org/abs/2112.09133) Chen Wei, Haoqi Fan, Saining Xie, Chao-Yuan Wu, Alan Yuille, Christoph Feichtenhofer
+ [Masked Image Modeling Advances 3D Medical Image Analysis](https://arxiv.org/abs/2204.11716)  Zekai Chen, Devansh Agarwal, Kshitij Aggarwal, Wiem Safta, Mariann Micsinai Balan, Venkat Sethuraman, Kevin Brown
+ [Masked Siamese Networks for Label-Efficient Learning](https://arxiv.org/abs/2204.07141) [:octocat:](https://github.com/facebookresearch/msn) Masked Siamese Networks for Label-Efficient Learning
+ [MaskGIT: Masked Generative Image Transformer](https://arxiv.org/abs/2202.04200) [:octocat:](https://github.com/google-research/maskgit) Huiwen Chang, Han Zhang, Lu Jiang, Ce Liu, William T. Freeman
+ [MLIM: Vision-and-Language Model Pre-training with Masked Language and Image Modeling](https://arxiv.org/abs/2109.12178) Tarik Arici, Mehmet Saygin Seyfioglu, Tal Neiman, Yi Xu, Son Train, Trishul Chilimbi, Belinda Zeng, Ismail Tutar
+ [SimMC: Simple Masked Contrastive Learning of Skeleton Representations for Unsupervised Person Re-Identification](https://arxiv.org/abs/2204.09826) [:octocat:](https://github.com/Kali-Hac/SimMC) Haocong Rao, Chunyan Miao
+ [VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training](https://arxiv.org/abs/2203.12602) [:octocat:](https://github.com/MCG-NJU/VideoMAE) Zhan Tong, Yibing Song, Jue Wang, Limin Wang
+ [What to Hide from Your Students: Attention-Guided Masked Image Modeling](https://arxiv.org/abs/2203.12719) Ioannis Kakogeorgiou, Spyros Gidaris, Bill Psomas, Yannis Avrithis, Andrei Bursuc, Konstantinos Karantzalos, Nikos Komodakis [:octocat:](https://github.com/gkakogeorgiou/attmask)
+ [Uniform Masking: Enabling MAE Pre-training for Pyramid-based Vision Transformers with Locality](https://arxiv.org/abs/2205.10063) [:octocat:](https://github.com/implus/UM-MAE) Xiang Li, Wenhai Wang, Lingfeng Yang, Jian Yang
+ [Self-supervised 3D anatomy segmentation using self-distilled masked image transformer (SMIT)](https://arxiv.org/abs/2205.10342) Jue Jiang, Neelam Tyagi, Kathryn Tringale, Christopher Crane, Harini Veeraraghavan
+ [FaceMAE: Privacy-Preserving Face Recognition via Masked Autoencoders](https://arxiv.org/abs/2205.11090) [:octocat:](https://github.com/kaiwang960112/FaceMAE) Kai Wang, Bo Zhao, Xiangyu Peng, Zheng Zhu, Jiankang Deng, Xinchao Wang, Hakan Bilen, Yang You
+ [Deeper vs Wider: A Revisit of Transformer Configuration](https://arxiv.org/abs/2205.10505) Fuzhao Xue, Jianghai Chen, Aixin Sun, Xiaozhe Ren, Zangwei Zheng, Xiaoxin He, Xin Jiang, Yang You
+ [Masked Conditional Video Diffusion for Prediction, Generation, and Interpolation](https://arxiv.org/abs/2205.09853) [:octocat:](https://github.com/voletiv/mcvd-pytorch) Vikram Voleti, Alexia Jolicoeur-Martineau, Christopher Pal
+ [Green Hierarchical Vision Transformer for Masked Image Modeling](https://arxiv.org/abs/2205.13515) [:octocat:](https://github.com/LayneH/GreenMIM) Lang Huang, Shan You, Mingkai Zheng, Fei Wang, Chen Qian, Toshihiko Yamasaki
+ [Revealing the Dark Secrets of Masked Image Modeling](https://arxiv.org/abs/2205.13543) Zhenda Xie, Zigang Geng, Jingcheng Hu, Zheng Zhang, Han Hu, Yue Cao
+ [MixMIM: Mixed and Masked Image Modeling for Efficient Visual Representation Learning](https://arxiv.org/abs/2205.13137) [:octocat:](https://github.com/Sense-X/MixMIM) Jihao Liu, Xin Huang, Yu Liu, Hongsheng Li
+ [Contrastive Learning Rivals Masked Image Modeling in Fine-tuning via Feature Distillation](https://arxiv.org/abs/2205.14141) [:octocat:](https://github.com/SwinTransformer/Feature-Distillation) Yixuan Wei, Han Hu, Zhenda Xie, Zheng Zhang, Yue Cao, Jianmin Bao, Dong Chen, Baining Guo
+ [Architecture-Agnostic Masked Image Modeling -- From ViT back to CNN](https://arxiv.org/abs/2205.13943) [:octocat:](https://github.com/Westlake-AI/openmixup) Siyuan Li, Di Wu, Fang Wu, Zelin Zang, Kai Wang, Lei Shang, Baigui Sun, Hao Li, Stan.Z.Li
+ [SupMAE: Supervised Masked Autoencoders Are Efficient Vision Learners](https://arxiv.org/abs/2205.14540) [:octocat:](https://github.com/cmu-enyac/supmae)  Feng Liang, Yangguang Li, Diana Marculescu
+ [Object-wise Masked Autoencoders for Fast Pre-training](https://arxiv.org/abs/2205.14338) Jiantao Wu, Shentong Mo
+ [Multimodal Masked Autoencoders Learn Transferable Representations](https://arxiv.org/abs/2205.14204) Xinyang Geng, Hao Liu, Lisa Lee, Dale Schuurmans, Sergey Levine, Pieter Abbeel
+ [MaskOCR: Text Recognition with Masked Encoder-Decoder Pretraining](https://arxiv.org/abs/2206.00311) Pengyuan Lyu, Chengquan Zhang, Shanshan Liu, Meina Qiao, Yangliu Xu, Liang Wu, Kun Yao, Junyu Han, Errui Ding, Jingdong Wang
+ [Mask DINO: Towards A Unified Transformer-based Framework for Object Detection and Segmentation](https://arxiv.org/abs/2206.02777) [:octocat:](https://github.com/IDEACVR/MaskDINO) Feng Li, Hao Zhang, Huaizhe xu, Shilong Liu, Lei Zhang, Lionel M. Ni, Heung-Yeung Shum
+ [Efficient Self-supervised Vision Pretraining with Local Masked Reconstruction](https://arxiv.org/abs/2206.00790) Jun Chen, Ming Hu, Boyang Li, Mohamed Elhoseiny
+ [Masked Unsupervised Self-training for Zero-shot Image Classification](https://arxiv.org/abs/2206.02967) [:octocat:](https://github.com/salesforce/MUST) Junnan Li, Silvio Savarese, Steven C.H. Hoi
+ [On Data Scaling in Masked Image Modeling](https://arxiv.org/abs/2206.04664) Zhenda Xie, Zheng Zhang, Yue Cao, Yutong Lin, Yixuan Wei, Qi Dai, Han Hu
+ [Draft-and-Revise: Effective Image Generation with Contextual RQ-Transformer](https://arxiv.org/abs/2206.04452) [:octocat:](https://github.com/kakaobrain/rq-vae-transformer) Doyup Lee, Chiheon Kim, Saehoon Kim, Minsu Cho, Wook-Shin Han
+ [Layered Depth Refinement with Mask Guidance](https://arxiv.org/abs/2206.03048) [:octocat:](https://sooyekim.github.io/MaskDepth/) Soo Ye Kim, Jianming Zhang, Simon Niklaus, Yifei Fan, Simon Chen, Zhe Lin, Munchurl Kim
+ [MVP: Multimodality-guided Visual Pre-training](https://arxiv.org/abs/2203.05175) Longhui Wei, Lingxi Xie, Wengang Zhou, Houqiang Li, Qi Tian
+ [Masked Autoencoders are Robust Data Augmentors](https://arxiv.org/abs/2206.04846) [:octocat:](https://github.com/haohang96/MRA) Haohang Xu, Shuangrui Ding, Xiaopeng Zhang, Hongkai Xiong, Qi Tian
+ [Discovering Object Masks with Transformers for Unsupervised Semantic Segmentation](https://arxiv.org/abs/2206.06363) [:octocat:](https://github.com/wvangansbeke/MaskDistill) Wouter Van Gansbeke, Simon Vandenhende, Luc Van Gool
+ [Masked Frequency Modeling for Self-Supervised Visual Pre-Training](https://arxiv.org/abs/2206.07706) [:octocat:](https://www.mmlab-ntu.com/project/mfm/index.html) Jiahao Xie, Wei Li, Xiaohang Zhan, Ziwei Liu, Yew Soon Ong, Chen Change Loy
+ [Adapting Self-Supervised Vision Transformers by Probing Attention-Conditioned Masking Consistency](https://arxiv.org/abs/2206.08222) [:octocat:](https://github.com/virajprabhu/PACMAC) Viraj Prabhu, Sriram Yenamandra, Aaditya Singh, Judy Hoffman
+ [OmniMAE: Single Model Masked Pretraining on Images and Videos](https://arxiv.org/abs/2206.08356) [:octocat:](https://github.com/facebookresearch/omnivore) Rohit Girdhar, Alaaeldin El-Nouby, Mannat Singh, Kalyan Vasudev Alwala, Armand Joulin, Ishan Misra
+ [A Unified Framework for Masked and Mask-Free Face Recognition via Feature Rectification](https://arxiv.org/abs/2202.07358) [:octocat:](https://github.com/haoosz/FFR-Net) Shaozhe Hao, Chaofeng Chen, Zhenfang Chen, Kwan-Yee K. Wong
+ [Integral Migrating Pre-trained Transformer Encoder-decoders for Visual Object Detection](https://arxiv.org/abs/2205.09613) Xiaosong Zhang, Feng Liu, Zhiliang Peng, Zonghao Guo, Fang Wan, Xiangyang Ji, Qixiang Ye
+ [SemMAE: Semantic-Guided Masking for Learning Masked Autoencoders](https://arxiv.org/abs/2206.10207) Gang Li, Heliang Zheng, Daqing Liu, Bing Su, Changwen Zheng
+ [Voxel-MAE: Masked Autoencoders for Pre-training Large-scale Point Clouds](https://arxiv.org/abs/2206.09900) [:octocat:](https://github.com/chaytonmin/Voxel-MAE) Chen Min, Dawei Zhao, Liang Xiao, Yiming Nie, Bin Dai
+ [MaskViT: Masked Visual Pre-Training for Video Prediction](https://arxiv.org/abs/2206.11894) [:octocat:](https://maskedvit.github.io/) Agrim Gupta, Stephen Tian, Yunzhi Zhang, Jiajun Wu, Roberto Mart√≠n-Mart√≠n, Li Fei-Fei
+ [Masked World Models for Visual Control](https://arxiv.org/abs/2206.14244) [:octocat:](https://sites.google.com/view/mwm-rl) Younggyo Seo, Danijar Hafner, Hao Liu, Fangchen Liu, Stephen James, Kimin Lee, Pieter Abbeel
+ [Masked Autoencoders are Robust Data Augmentors](https://arxiv.org/abs/2206.04846) [:octocat:](https://github.com/haohang96/MRA) Haohang Xu, Shuangrui Ding, Xiaopeng Zhang, Hongkai Xiong, Qi Tian
+ [Masked Autoencoders for Self-Supervised Learning on Automotive Point Clouds](https://arxiv.org/abs/2207.00531) [:octocat:](https://github.com/georghess/voxel-mae) Georg Hess, Johan Jaxing, Elias Svensson, David Hagerman, Christoffer Petersson, Lennart Svensson
+ [Training Vision-Language Transformers from Captions Alone](https://arxiv.org/abs/2205.09256) [:octocat:](https://github.com/guilk/VLC) Liangke Gui, Qiuyuan Huang, Alex Hauptmann, Yonatan Bisk, Jianfeng Gao
+ [Masked Generative Distillation](https://arxiv.org/abs/2205.01529) [:octocat:](https://github.com/yzd-v/MGD) Zhendong Yang, Zhe Li, Mingqi Shao, Dachuan Shi, Zehuan Yuan, Chun Yuan
+ [k-means Mask Transformer](https://arxiv.org/abs/2207.04044) [:octocat:](https://github.com/google-research/deeplab2) Qihang Yu, Huiyu Wang, Siyuan Qiao, Maxwell Collins, Yukun Zhu, Hatwig Adam, Alan Yuille, Liang-Chieh Chen
+ [Bootstrapped Masked Autoencoders for Vision BERT Pretraining](https://arxiv.org/abs/2207.07116) [:octocat:](https://github.com/LightDXY/BootMAE) Xiaoyi Dong, Jianmin Bao, Ting Zhang, Dongdong Chen, Weiming Zhang, Lu Yuan, Dong Chen, Fang Wen, Nenghai Yu
+ [SatMAE: Pre-training Transformers for Temporal and Multi-Spectral Satellite Imagery](https://arxiv.org/abs/2207.08051) [:octocat:](https://github.com/sustainlab-group/SatMAE) Yezhen Cong, Samar Khanna, Chenlin Meng, Patrick Liu, Erik Rozi, Yutong He, Marshall Burke, David B. Lobell, Stefano Ermon
+ [Contrastive Masked Autoencoders are Stronger Vision Learners](https://arxiv.org/abs/2207.13532) Zhicheng Huang, Xiaojie Jin, Chengze Lu, Qibin Hou, Ming-Ming Cheng, Dongmei Fu, Xiaohui Shen, Jiashi Feng
+ [Masked Discrimination for Self-Supervised Learning on Point Clouds](https://arxiv.org/abs/2203.11183) [:octocat:](https://github.com/haotian-liu/MaskPoint) Haotian Liu, Mu Cai, Yong Jae Lee
+ [SdAE: Self-distillated Masked Autoencoder](https://arxiv.org/abs/2208.00449) [:octocat:](https://github.com/AbrahamYabo/SdAE) Yabo Chen, Yuchen Liu, Dongsheng Jiang, Xiaopeng Zhang, Wenrui Dai, Hongkai Xiong, Qi Tian
+ [Less is More: Consistent Video Depth Estimation with Masked Frames Modeling](https://arxiv.org/abs/2208.00380) Yiran Wang, Zhiyu Pan, Xingyi Li, Zhiguo Cao, Ke Xian, Jianming Zhang
+ [Masked Vision and Language Modeling for Multi-modal Representation Learning](https://arxiv.org/abs/2208.02131) Gukyeong Kwon, Zhaowei Cai, Avinash Ravichandran, Erhan Bas, Rahul Bhotika, Stefano Soatto
+ [Masked Feature Prediction for Self-Supervised Visual Pre-Training](https://arxiv.org/abs/2112.09133) [:octocat:](https://github.com/facebookresearch/pytorchvideo) Chen Wei, Haoqi Fan, Saining Xie, Chao-Yuan Wu, Alan Yuille, Christoph Feichtenhofer
+ [Understanding Masked Image Modeling via Learning Occlusion Invariant Feature](https://arxiv.org/abs/2208.04164) Xiangwen Kong, Xiangyu Zhang
+ [BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers](https://arxiv.org/abs/2208.06366) [:octocat:](https://github.com/microsoft/unilm/tree/master/beit) Zhiliang Peng, Li Dong, Hangbo Bao, Qixiang Ye, Furu Wei
+ [MILAN: Masked Image Pretraining on Language Assisted Representation](https://arxiv.org/abs/2208.06049) [:octocat:](https://github.com/zejiangh/MILAN) Zejiang Hou, Fei Sun, Yen-Kuang Chen, Yuan Xie, Sun-Yuan Kung
+ [Open-Vocabulary Panoptic Segmentation with MaskCLIP](https://arxiv.org/abs/2208.08984) Zheng Ding, Jieke Wang, Zhuowen Tu
+ [VLMAE: Vision-Language Masked Autoencoder](https://arxiv.org/abs/2208.09374) Sunan He, Taian Guo, Tao Dai, Ruizhi Qiao, Chen Wu, Xiujun Shu, Bo Ren
+ [MaskCLIP: Masked Self-Distillation Advances Contrastive Language-Image Pretraining](https://arxiv.org/abs/2208.12262) Xiaoyi Dong, Yinglin Zheng, Jianmin Bao, Ting Zhang, Dongdong Chen, Hao Yang, Ming Zeng, Weiming Zhang, Lu Yuan, Dong Chen, Fang Wen, Nenghai Yu
+ [Masked Autoencoders Enable Efficient Knowledge Distillers](https://arxiv.org/abs/2208.12256) [:octocat:](https://github.com/UCSC-VLAA/DMAE) Yutong Bai, Zeyu Wang, Junfei Xiao, Chen Wei, Huiyu Wang, Alan Yuille, Yuyin Zhou, Cihang Xie
+ [Multi-Modal Masked Autoencoders for Medical Vision-and-Language Pre-Training](https://arxiv.org/abs/2209.07098) [:octocat:](https://github.com/zhjohnchan/M3AE) Zhihong Chen, Yuhao Du, Jinpeng Hu, Yang Liu, Guanbin Li, Xiang Wan, Tsung-Hui Chang
+ [MetaMask: Revisiting Dimensional Confounder for Self-Supervised Learning](https://arxiv.org/abs/2209.07902) [:octocat:](https://github.com/lionellee9089/MetaMask) Jiangmeng Li, Wenwen Qiang, Yanan Zhang, Wenyi Mo, Changwen Zheng, Bing Su, Hui Xiong
+ [NamedMask: Distilling Segmenters from Complementary Foundation Models](https://arxiv.org/abs/2209.11228) [:octocat:](https://github.com/NoelShin/namedmask) Gyungin Shin, Weidi Xie, Samuel Albanie
+ [Exploring Target Representations for Masked Autoencoders](https://arxiv.org/abs/2209.03917) Xingbin Liu, Jinghao Zhou, Tao Kong, Xianming Lin, Rongrong Ji
+ [Self-Supervised Masked Convolutional Transformer Block for Anomaly Detection](https://arxiv.org/abs/2209.12148) [:octocat:](https://github.com/ristea/ssmctb) Neelu Madan, Nicolae-Catalin Ristea, Radu Tudor Ionescu, Kamal Nasrollahi, Fahad Shahbaz Khan, Thomas B. Moeslund, Mubarak Shah
+ [Exploring The Role of Mean Teachers in Self-supervised Masked Auto-Encoders](https://arxiv.org/abs/2210.02077) Youngwan Lee, Jeffrey Willette, Jonghee Kim, Juho Lee, Sung Ju Hwang
+ [Self-Distillation for Further Pre-training of Transformers](https://arxiv.org/abs/2210.02871) Seanie Lee, Minki Kang, Juho Lee, Sung Ju Hwang, Kenji Kawaguchi
+ [MAMO: Masked Multimodal Modeling for Fine-Grained Vision-Language Representation Learning](https://arxiv.org/abs/2210.04183) Zijia Zhao, Longteng Guo, Xingjian He, Shuai Shao, Zehuan Yuan, Jing Liu
+ [It Takes Two: Masked Appearance-Motion Modeling for Self-supervised Video Transformer Pre-training](https://arxiv.org/abs/2210.05234) Yuxin Song, Min Yang, Wenhao Wu, Dongliang He, Fu Li, Jingdong Wang
+ [Exploring Long-Sequence Masked Autoencoders](https://arxiv.org/abs/2210.07224) [:octocat:](https://github.com/facebookresearch/long_seq_mae) Ronghang Hu, Shoubhik Debnath, Saining Xie, Xinlei Chen
+ [Denoising Masked AutoEncoders are Certifiable Robust Vision Learners](https://arxiv.org/abs/2210.06983) [:octocat:](https://github.com/quanlin-wu/dmae) Quanlin Wu, Hang Ye, Yuntian Gu, Huishuai Zhang, Liwei Wang, Di He
+ [M3Video: Masked Motion Modeling for Self-Supervised Video Representation Learning](https://arxiv.org/abs/2210.06096) Xinyu Sun, Peihao Chen, Liangwei Chen, Thomas H. Li, Mingkui Tan, Chuang Gan
+ [Ensemble Learning using Transformers and Convolutional Networks for Masked Face Recognition](https://arxiv.org/abs/2210.04816) [:octocat:](https://github.com/Hamzah-Luqman/MFR) Mohammed R. Al-Sinan, Aseel F. Haneef, Hamzah Luqman
+ [MOVE: Unsupervised Movable Object Segmentation and Detection](https://arxiv.org/abs/2210.07920) Adam Bielski, Paolo Favaro
+ [Denoising Masked AutoEncoders are Certifiable Robust Vision Learners](https://arxiv.org/abs/2210.06983) [:octocat:](https://github.com/quanlin-wu/dmae) Quanlin Wu, Hang Ye, Yuntian Gu, Huishuai Zhang, Liwei Wang, Di He
+ [How Mask Matters: Towards Theoretical Understandings of Masked Autoencoders](https://arxiv.org/abs/2210.08344) [:octocat:](https://github.com/zhangq327/U-MAE) Qi Zhang, Yifei Wang, Yisen Wang
+ [MultiMAE: Multi-modal Multi-task Masked Autoencoders](https://arxiv.org/abs/2204.01678) [:octocat:](https://github.com/EPFL-VILAB/MultiMAE) [üåê](https://multimae.epfl.ch/) Roman Bachmann, David Mizrahi, Andrei Atanov, Amir Zamir
+ [A Unified View of Masked Image Modeling](https://arxiv.org/abs/2210.10615) [:octocat:](https://github.com/microsoft/unilm/tree/master/unimim) Zhiliang Peng, Li Dong, Hangbo Bao, Qixiang Ye, Furu Wei
+ [i-MAE: Are Latent Representations in Masked Autoencoders Linearly Separable?](https://arxiv.org/abs/2210.11470) [:octocat:](https://github.com/vision-learning-acceleration-lab/i-mae) Kevin Zhang, Zhiqiang Shen
+ [MixMask: Revisiting Masked Siamese Self-supervised Learning in Asymmetric Distance](https://arxiv.org/abs/2210.11456) [:octocat:](https://github.com/LightnessOfBeing/MixMask) Kirill Vishniakov, Eric Xing, Zhiqiang Shen
+ [DiffEdit: Diffusion-based semantic image editing with mask guidance](https://arxiv.org/abs/2210.11427) Guillaume Couairon, Jakob Verbeek, Holger Schwenk, Matthieu Cord
+ [Masked Modeling Duo: Learning Representations by Encouraging Both Networks to Model the Input](https://arxiv.org/abs/2210.14648) Daisuke Niizumi, Daiki Takeuchi, Yasunori Ohishi, Noboru Harada, Kunio Kashino
+ [A simple, efficient and scalable contrastive masked autoencoder for learning visual representations](https://arxiv.org/abs/2210.16870) Shlok Mishra, Joshua Robinson, Huiwen Chang, David Jacobs, Aaron Sarna, Aaron Maschinot, Dilip Krishnan
+ [Siamese Transition Masked Autoencoders as Uniform Unsupervised Visual Anomaly Detector](https://arxiv.org/abs/2211.00349) Haiming Yao, Xue Wang, Wenyong Yu
+ [Bootstrapped Masked Autoencoders for Vision BERT Pretraining](https://arxiv.org/abs/2207.07116v1) [:octocat:](https://github.com/LightDXY/BootMAE) Xiaoyi Dong, Jianmin Bao, Ting Zhang, Dongdong Chen, Weiming Zhang, Lu Yuan, Dong Chen, Fang Wen, Nenghai Yu
+ [MaskTune: Mitigating Spurious Correlations by Forcing to Explore](https://arxiv.org/abs/2210.00055) [:octocat:](https://github.com/aliasgharkhani/Masktune) Saeid Asgari Taghanaki, Aliasghar Khani, Fereshte Khani, Ali Gholami, Linh Tran, Ali Mahdavi-Amiri, Ghassan Hamarneh
+ [Exploring the Limits of Masked Visual Representation Learning at Scale](https://arxiv.org/abs/2211.07636) [:octocat:](https://github.com/baaivision/EVA) Yuxin Fang, Wen Wang, Binhui Xie, Quan Sun, Ledell Wu, Xinggang Wang, Tiejun Huang, Xinlong Wang, Yue Cao
+ [MAGE: MAsked Generative Encoder to Unify Representation Learning and Image Synthesis](https://arxiv.org/abs/2211.09117) [:octocat:](https://github.com/LTH14/mage) Tianhong Li, Huiwen Chang, Shlok Kumar Mishra, Han Zhang, Dina Katabi, Dilip Krishnan
+ [Stare at What You See: Masked Image Modeling without Reconstruction](https://arxiv.org/abs/2211.08887) [:octocat:](https://github.com/OpenPerceptionX/maskalign) Hongwei Xue, Peng Gao, Hongyang Li, Yu Qiao, Hao Sun, Houqiang Li, Jiebo Luo
+ [Mask-based Latent Reconstruction for Reinforcement Learning](https://arxiv.org/abs/2201.12096) [:octocat:](https://github.com/microsoft/Mask-based-Latent-Reconstruction) Tao Yu, Zhizheng Zhang, Cuiling Lan, Yan Lu, Zhibo Chen
+ [AdaMAE: Adaptive Masking for Efficient Spatiotemporal Learning with Masked Autoencoders](https://arxiv.org/abs/2211.09120v1) [:octocat:](https://github.com/wgcban/adamae) Wele Gedara Chaminda Bandara, Naman Patel, Ali Gholami, Mehdi Nikkhah, Motilal Agrawal, Vishal M. Patel
+ [Efficient Video Representation Learning via Masked Video Modeling with Motion-centric Token Selection](https://arxiv.org/abs/2211.10636) [:octocat:](https://github.com/sunilhoho/VideoMS) Sunil Hwang, Jaehong Yoon, Youngwan Lee, Sung Ju Hwang
+ [Contrastive Masked Autoencoders for Self-Supervised Video Hashing](https://arxiv.org/abs/2211.11210) [:octocat:](https://github.com/huangmozhi9527/ConMH) Yuting Wang, Jinpeng Wang, Bin Chen, Ziyun Zeng, Shutao Xia
+ [MCVD: Masked Conditional Video Diffusion for Prediction, Generation, and Interpolation](https://arxiv.org/abs/2205.09853) [üåê](https://mask-cond-video-diffusion.github.io/) [:octocat:](https://github.com/voletiv/mcvd-pytorch) Vikram Voleti, Alexia Jolicoeur-Martineau, Christopher Pal
+ [MAEDAY: MAE for few and zero shot AnomalY-Detection](https://arxiv.org/abs/2211.14307) [:octocat:](https://github.com/EliSchwartz/MAEDAY) Eli Schwartz, Assaf Arbelle, Leonid Karlinsky, Sivan Harary, Florian Scheidegger, Sivan Doveh, Raja Giryes
+ [What's Behind the Mask: Estimating Uncertainty in Image-to-Image Problems](https://arxiv.org/abs/2211.15211) Gilad Kutiel, Regev Cohen, Michael Elad, Daniel Freedman
+ [Good helper is around you: Attention-driven Masked Image Modeling](https://arxiv.org/abs/2211.15362) Jie Gui, Zhengqi Liu, Hao Luo
+ [Scaling Language-Image Pre-training via Masking](https://arxiv.org/abs/2212.00794) Yanghao Li, Haoqi Fan, Ronghang Hu, Christoph Feichtenhofer, Kaiming He
+ [Learning Imbalanced Data with Vision Transformers](https://arxiv.org/abs/2212.02015) [:octocat:](https://github.com/XuZhengzhuo/LiVT) Zhengzhuo Xu, Ruikang Liu, Shuo Yang, Zenghao Chai, Chun Yuan
+ [Masked Contrastive Pre-Training for Efficient Video-Text Retrieval](https://arxiv.org/abs/2212.00986) Fangxun Shu, Biaolong Chen, Yue Liao, Shuwen Xiao, Wenyu Sun, Xiaobo Li, Yousong Zhu, Jinqiao Wang, Si Liu
+ [MIC: Masked Image Consistency for Context-Enhanced Domain Adaptation](https://arxiv.org/abs/2212.01322) [:octocat:](https://github.com/lhoyer/MIC) Lukas Hoyer, Dengxin Dai, Haoran Wang, Luc Van Gool
+ [Masked Video Distillation: Rethinking Masked Feature Modeling for Self-supervised Video Representation Learning](https://arxiv.org/abs/2212.04500) [üåê](https://github.com/ruiwang2021/mvd) Rui Wang, Dongdong Chen, Zuxuan Wu, Yinpeng Chen, Xiyang Dai, Mengchen Liu, Lu Yuan, Yu-Gang Jiang
+ [MAGVIT: Masked Generative Video Transformer](https://arxiv.org/abs/2212.05199) [üåê](https://magvit.cs.cmu.edu/) Lijun Yu, Yong Cheng, Kihyuk Sohn, Jos√© Lezama, Han Zhang, Huiwen Chang, Alexander G. Hauptmann, Ming-Hsuan Yang, Yuan Hao, Irfan Essa, Lu Jiang
+ [FastMIM: Expediting Masked Image Modeling Pre-training for Vision](https://arxiv.org/abs/2212.06593) [:octocat:](https://github.com/ggjy/FastMIM.pytorch) Jianyuan Guo, Kai Han, Han Wu, Yehui Tang, Yunhe Wang, Chang Xu
+ [Learning 3D Representations from 2D Pre-trained Models via Image-to-Point Masked Autoencoders](https://arxiv.org/abs/2212.06785) [:octocat:](https://github.com/ZrrSkywalker/I2P-MAE) Renrui Zhang, Liuhui Wang, Yu Qiao, Peng Gao, Hongsheng Li
+ [Efficient Self-supervised Learning with Contextualized Target Representations for Vision, Speech and Language](https://arxiv.org/abs/2212.07525) [:octocat:](https://github.com/facebookresearch/fairseq/tree/main/examples/data2vec) Alexei Baevski, Arun Babu, Wei-Ning Hsu, Michael Auli
+ [Swin MAE: Masked Autoencoders for Small Datasets](https://arxiv.org/abs/2212.13805) Zi'an Xu, Yin Dai, Fayu Liu, Weibing Chen, Yue Liu, Lifu Shi, Sheng Liu, Yuhang Zhou
+ [Semi-MAE: Masked Autoencoders for Semi-supervised Vision Transformers](https://arxiv.org/abs/2301.01431) Haojie Yu, Kang Zhao, Xiaoming Xu
+ [MS-DINO: Efficient Distributed Training of Vision Transformer Foundation Model in Medical Domain through Masked Sampling](https://arxiv.org/abs/2301.02064) Sangjoon Park, Ik-Jae Lee, Jun Won Kim, Jong Chul Ye
+ [BEV-MAE: Bird's Eye View Masked Autoencoders for Outdoor Point Cloud Pre-training](https://arxiv.org/abs/2212.05758) Zhiwei Lin, Yongtao Wang


# Audio
+ [MAE-AST: Masked Autoencoding Audio Spectrogram Transformer](https://arxiv.org/abs/2203.16691) [:octocat:](https://github.com/AlanBaade/MAE-AST-Public) Alan Baade, Puyuan Peng, David Harwath
+ [Group masked autoencoder based density estimator for audio anomaly detection](https://www.amazon.science/publications/group-masked-autoencoder-based-density-estimator-for-audio-anomaly-detection) Ritwik Giri, Fangzhou Cheng, Karim Helwani, Srikanth V. Tenneti, Umut Isik, Arvindh Krishnaswamy
+ [Masked Autoencoders that Listen](https://arxiv.org/abs/2207.06405) [:octocat:](https://github.com/facebookresearch/AudioMAE) Po-Yao (Bernie)Huang, Hu Xu, Juncheng Li, Alexei Baevski, Michael Auli, Wojciech Galuba, Florian Metze, Christoph Feichtenhofer
+ [Efficient Vision-Language Pretraining with Visual Concepts and Hierarchical Alignment](https://arxiv.org/abs/2208.13628) [:octocat:](https://github.com/mshukor/ViCHA) Mustafa Shukor, Guillaume Couairon, Matthieu Cord
+ [Contrastive Audio-Visual Masked Autoencoder](https://arxiv.org/abs/2210.07839) Yuan Gong, Andrew Rouditchenko, Alexander H. Liu, David Harwath, Leonid Karlinsky, Hilde Kuehne, James Glass
+ [Masked Spectrogram Modeling using Masked Autoencoders for Learning General-purpose Audio Representation](https://arxiv.org/abs/2204.12260) [:octocat:](https://github.com/nttcslab/msm-mae) Daisuke Niizumi, Daiki Takeuchi, Yasunori Ohishi, Noboru Harada, Kunio Kashino
+ [Masked Lip-Sync Prediction by Audio-Visual Contextual Exploitation in Transformers](https://arxiv.org/abs/2212.04970) [:octocat:](https://hangz-nju-cuhk.github.io/projects/AV-CAT) Yasheng Sun, Hang Zhou, Kaisiyuan Wang, Qianyi Wu, Zhibin Hong, Jingtuo Liu, Errui Ding, Jingdong Wang, Ziwei Liu, Hideki Koike
+ [Audiovisual Masked Autoencoders](https://arxiv.org/abs/2212.05922) Mariana-Iuliana Georgescu, Eduardo Fonseca, Radu Tudor Ionescu, Mario Lucic, Cordelia Schmid, Anurag Arnab
+ [TinyMIM: An Empirical Study of Distilling MIM Pre-trained Models](https://arxiv.org/abs/2301.01296) [:octocat:](https://github.com/OliverRensu/TinyMIM)  Sucheng Ren, Fangyun Wei, Zheng Zhang, Han Hu
+ [ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders](https://arxiv.org/abs/2301.00808) [:octocat:](https://github.com/facebookresearch/ConvNeXt-V2) Sanghyun Woo, Shoubhik Debnath, Ronghang Hu, Xinlei Chen, Zhuang Liu, In So Kweon, Saining Xie
+ [Disjoint Masking with Joint Distillation for Efficient Masked Image Modeling](https://arxiv.org/abs/2301.00230) [:octocat:](https://github.com/mx-mark/DMJD) Xin Ma, Chang Liu, Chunyu Xie, Long Ye, Yafeng Deng, Xiangyang Ji




# Graph
+ [MGAE: Masked Autoencoders for Self-Supervised Learning on Graphs](https://arxiv.org/abs/2201.02534) [:octocat:](https://github.com/Qiaoyut/MGAE) Qiaoyu Tan, Ninghao Liu, Xiao Huang, Rui Chen, Soo-Hyun Choi, Xia Hu
+ [Graph Masked Autoencoder with Transformers](https://arxiv.org/abs/2202.08391) [:octocat:](https://github.com/RinneSz/GMAE) Sixiao Zhang, Hongxu Chen, Haoran Yang, Xiangguo Sun, Philip S. Yu, Guandong Xu
+ [MaskGAE: Masked Graph Modeling Meets Graph Autoencoders](https://arxiv.org/abs/2205.10053) [:octocat:](https://github.com/EdisonLeeeee/MaskGAE) Jintang Li, Ruofan Wu, Wangbin Sun, Liang Chen, Sheng Tian, Liang Zhu, Changhua Meng, Zibin Zheng, Weiqiang Wang
+ [GraphMAE: Self-Supervised Masked Graph Autoencoders](https://arxiv.org/abs/2205.10803) [:octocat:](https://github.com/THUDM/GraphMAE) Zhenyu Hou, Xiao Liu, Yukuo Cen, Yuxiao Dong, Hongxia Yang, Chunjie Wang, Jie Tang
+ [Heterogeneous Graph Masked Autoencoders](https://arxiv.org/abs/2208.09957) Yijun Tian, Kaiwen Dong, Chunhui Zhang, Chuxu Zhang, Nitesh V. Chawla
+ [Graph Masked Autoencoder Enhanced Predictor for Neural Architecture Search](https://www.ijcai.org/proceedings/2022/432) [:octocat:](https://github.com/kunjing96/GMAENAS.git) Kun Jing , Jungang Xu, Pengfei Li
+ [Bi-channel Masked Graph Autoencoders for Spatially Resolved Single-cell Transcriptomics Data Imputation](https://openreview.net/pdf?id=LGFbhnR4U33)  Hongzhi Wen, Wei Jin, Jiayuan Ding, Christopher Xu, Yuying Xie, Jiliang Tang
+ [Masked Graph Auto-Encoder Constrained Graph Pooling](https://2022.ecmlpkdd.org/wp-content/uploads/2022/09/sub_542.pdf) [:octocat:](https://github.com/liucoo/mgap) Chuang Liu, Yibing Zhan, Xueqi Ma, Dapeng Tao, Bo Du, Wenbin Hu 
+ [BatmanNet: Bi-branch Masked Graph Transformer Autoencoder for Molecular Representation](https://arxiv.org/abs/2211.13979) Zhen Wang, Zheng Feng, Yanjun Li, Bowen Li, Yongrui Wang, Chulin Sha, Min He, Xiaolin Li
+ [Jointly Learning Visual and Auditory Speech Representations from Raw Data](https://arxiv.org/abs/2212.06246) Alexandros Haliassos, Pingchuan Ma, Rodrigo Mira, Stavros Petridis, Maja Pantic


# Language (Omitted)
There has been a surge of language research focused on such masking-and-predicting paradigm, e.g. BERT, so I'm not going to report these works.

# Miscellaneous
+ [Point-M2AE: Multi-scale Masked Autoencoders for Hierarchical Point Cloud Pre-training](https://arxiv.org/abs/2205.14401) [:octocat:](https://github.com/ZrrSkywalker/Point-M2AE) Renrui Zhang, Ziyu Guo, Peng Gao, Rongyao Fang, Bin Zhao, Dong Wang, Yu Qiao, Hongsheng Li
+ [Masked Bayesian Neural Networks : Computation and Optimality](https://arxiv.org/abs/2206.00853) Insung Kong, Dongyoon Yang, Jongjin Lee, Ilsang Ohn, Yongdai Kim
+ [How to Understand Masked Autoencoders](https://arxiv.org/abs/2202.03670) Shuhao Cao, Peng Xu, David A. Clifton
+ [Towards Understanding Why Mask-Reconstruction Pretraining Helps in Downstream Tasks](https://arxiv.org/abs/2206.03826) Jiachun Pan, Pan Zhou, Shuicheng Yan
+ [MET: Masked Encoding for Tabular Data](https://arxiv.org/abs/2206.08564) Kushal Majmundar, Sachin Goyal, Praneeth Netrapalli, Prateek Jain
+ [Masked Self-Supervision for Remaining Useful Lifetime Prediction in Machine Tools](https://arxiv.org/abs/2207.01219) Haoren Guo, Haiyue Zhu, Jiahui Wang, Vadakkepat Prahlad, Weng Khuen Ho, Tong Heng Lee
+ [MAR: Masked Autoencoders for Efficient Action Recognition](https://arxiv.org/abs/2207.11660) [:octocat:](https://github.com/alibaba-mmai-research/Masked-Action-Recognition) Zhiwu Qing, Shiwei Zhang, Ziyuan Huang, Xiang Wang, Yuehuan Wang, Yiliang Lv, Changxin Gao, Nong Sang
+ [MeshMAE: Masked Autoencoders for 3D Mesh Data Analysis](https://arxiv.org/abs/2207.10228) [:octocat:](https://github.com/liang3588/MeshMAE) Yaqian Liang, Shanshan Zhao, Baosheng Yu, Jing Zhang, Fazhi He
+ [A Dual-Masked Auto-Encoder for Robust Motion Capture with Spatial-Temporal Skeletal Token Completion](https://arxiv.org/abs/2207.07381) [:octocat:](https://github.com/HKBU-VSComputing/2022_MM_DMAE-Mocap) Junkun Jiang, Jie Chen, Yike Guo
+ [Survey] [A Survey on Masked Autoencoder for Self-supervised Learning in Vision and Beyond](https://arxiv.org/abs/2208.00173) Chaoning Zhang, Chenshuang Zhang, Junha Song, John Seon Keun Yi, Kang Zhang, In So Kweon
+ [Masked Imitation Learning: Discovering Environment-Invariant Modalities in Multimodal Demonstrations](https://arxiv.org/abs/2209.07682) [:octocat:](https://sites.google.com/view/mask-imitation-learning) Yilun Hao, Ruinan Wang, Zhangjie Cao, Zihan Wang, Yuchen Cui, Dorsa Sadigh
+ [Real-World Robot Learning with Masked Visual Pre-training](https://arxiv.org/abs/2210.03109) [:octocat:](https://tetexiao.com/projects/real-mvp) Ilija Radosavovic, Tete Xiao, Stephen James, Pieter Abbeel, Jitendra Malik, Trevor Darrell
+ [Self-supervised Video Representation Learning with Motion-Aware Masked Autoencoders](https://arxiv.org/abs/2210.04154) [:octocat:](https://github.com/happy-hsy/MotionMAE) Haosen Yang, Deng Huang, Bin Wen, Jiannan Wu, Hongxun Yao, Yi Jiang, Xiatian Zhu, Zehuan Yuan
+ [MAEEG: Masked Auto-encoder for EEG Representation Learning](https://arxiv.org/abs/2211.02625) Hsiang-Yun Sherry Chien, Hanlin Goh, Christopher M. Sandino, Joseph Y. Cheng
+ [Masked Autoencoding for Scalable and Generalizable Decision Making](https://arxiv.org/abs/2211.12740) [:octocat:](https://github.com/FangchenLiu/MaskDP_public) Fangchen Liu, Hao Liu, Aditya Grover, Pieter Abbeel
+ [MHCCL: Masked Hierarchical Cluster-wise Contrastive Learning for Multivariate Time Series](https://arxiv.org/abs/2212.01141) [:octocat:](https://github.com/mqwfrog/MHCCL) Qianwen Meng, Hangwei Qian, Yong Liu, Yonghui Xu, Zhiqi Shen, Lizhen Cui
+ [GD-MAE: Generative Decoder for MAE Pre-training on LiDAR Point Clouds](https://arxiv.org/abs/2212.03010) [:octocat:](https://github.com/Nightmare-n/GD-MAE) Honghui Yang, Tong He, Jiaheng Liu, Hua Chen, Boxi Wu, Binbin Lin, Xiaofei He, Wanli Ouyang
+ [MAELi -- Masked Autoencoder for Large-Scale LiDAR Point Clouds](https://arxiv.org/abs/2212.07207) Georg Krispel, David Schinagl, Christian Fruhwirth-Reisinger, Horst Possegger, Horst Bischof





# TODO List
- [x] Add code links
- [x] Add authers list
- [ ] Add conference/journal venues
- [ ] Add more illustrative figures

